#!/bin/bash
# This script is used to configure and run Nomad on an AWS server.

set -e

source "/opt/gruntwork/bash-commons/log.sh"
source "/opt/gruntwork/bash-commons/string.sh"
source "/opt/gruntwork/bash-commons/assert.sh"
source "/opt/gruntwork/bash-commons/aws-wrapper.sh"

readonly NOMAD_CONFIG_FILE="default.hcl"
readonly SYSTEMD_CONFIG_PATH="/etc/systemd/system/nomad.service"

readonly EC2_INSTANCE_METADATA_URL="http://169.254.169.254/latest/meta-data"
readonly EC2_INSTANCE_DYNAMIC_DATA_URL="http://169.254.169.254/latest/dynamic"

readonly SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
readonly SCRIPT_NAME="$(basename "$0")"

readonly MAX_RETRIES=30
readonly SLEEP_BETWEEN_RETRIES_SEC=10

function print_usage {
  echo
  echo "Usage: run-nomad [OPTIONS]"
  echo
  echo "This script is used to configure and run Nomad on an AWS server."
  echo
  echo "Options:"
  echo
  echo -e "  --server\t\tIf set, run in server mode. Optional. At least one of --server or --client must be set."
  echo -e "  --client\t\tIf set, run in client mode. Optional. At least one of --server or --client must be set."
  echo -e "  --num-servers\t\tThe number of servers to expect in the Nomad cluster. Required if --server is true."
  echo -e "  --config-dir\t\tThe path to the Nomad config folder. Optional. Default is the absolute path of '../config', relative to this script."
  echo -e "  --data-dir\t\tThe path to the Nomad data folder. Optional. Default is the absolute path of '../data', relative to this script."
  echo -e "  --bin-dir\t\tThe path to the folder with Nomad binary. Optional. Default is the absolute path of the parent folder of this script."
  echo -e "  --systemd-stdout\t\tThe StandardOutput option of the systemd unit.  Optional.  If not configured, uses systemd's default (journal)."
  echo -e "  --systemd-stderr\t\tThe StandardError option of the systemd unit.  Optional.  If not configured, uses systemd's default (inherit)."
  echo -e "  --user\t\tThe user to run Nomad as. Optional. Default is to use the owner of --config-dir."
  echo -e "  --use-sudo\t\tIf set, run the Nomad agent with sudo. By default, sudo is only used if --client is set."
  echo -e "  --environment\t\A single environment variable in the key/value pair form 'KEY=\"val\"' to pass to Nomad as environment variable when starting it up. Repeat this option for additional variables. Optional."
  echo -e "  --node-class\t\tThe node_class to pass it to Nomad Clients. Optional. valid only if --client is true."
  echo -e "  --skip-nomad-config\tIf this flag is set, don't generate a Nomad configuration file. Optional. Default is false."
  echo
  echo "Example:"
  echo
  echo "  run-nomad --server --config-dir /custom/path/to/nomad/config"
}

function log {
  local readonly level="$1"
  local readonly message="$2"
  local readonly timestamp=$(date +"%Y-%m-%d %H:%M:%S")
  >&2 echo -e "${timestamp} [${level}] [$SCRIPT_NAME] ${message}"
}

function log_info {
  local readonly message="$1"
  log "INFO" "$message"
}

function log_warn {
  local readonly message="$1"
  log "WARN" "$message"
}

function log_error {
  local readonly message="$1"
  log "ERROR" "$message"
}

# Based on code from: http://stackoverflow.com/a/16623897/483528
function strip_prefix {
  local readonly str="$1"
  local readonly prefix="$2"
  echo "${str#$prefix}"
}

function assert_not_empty {
  local readonly arg_name="$1"
  local readonly arg_value="$2"

  if [[ -z "$arg_value" ]]; then
    log_error "The value for '$arg_name' cannot be empty"
    print_usage
    exit 1
  fi
}

function split_by_lines {
  local prefix="$1"
  shift

  for var in "$@"; do
    echo "${prefix}${var}"
  done
}

function get_metadata_token {
  curl --silent --show-error --location \
    --request PUT "$EC2_INSTANCE_METADATA_URL/../api/token" \
    --header "X-aws-ec2-metadata-token-ttl-seconds: 21600"
}

function lookup_path_in_instance_metadata {
  local -r path="$1"
  local -r token="$2"
  curl --silent --show-error --location --header "X-aws-ec2-metadata-token: $token" "$EC2_INSTANCE_METADATA_URL/$path/"
}

function lookup_path_in_instance_dynamic_data {
  local -r path="$1"
  local -r token="$2"
  curl --silent --show-error --location --header "X-aws-ec2-metadata-token: $token" "$EC2_INSTANCE_DYNAMIC_DATA_URL/$path/"
}

function get_instance_ip_address {
  lookup_path_in_instance_metadata "local-ipv4" "$1"
}

function get_instance_id {
  lookup_path_in_instance_metadata "instance-id" "$1"
}

function get_instance_availability_zone {
  lookup_path_in_instance_metadata "placement/availability-zone" "$1"
}

function get_instance_region {
  lookup_path_in_instance_dynamic_data "instance-identity/document" "$1" | jq -r ".region"
}

function assert_is_installed {
  local readonly name="$1"

  if [[ ! $(command -v ${name}) ]]; then
    log_error "The binary '$name' is required by this script but is not installed or in the system's PATH."
    exit 1
  fi
}

function get_instance_tags {
  local -r instance_id="$1"
  local -r instance_region="$2"
  local tags=""
  local count_tags=""

  log_info "Looking up tags for Instance $instance_id in $instance_region"
  for ((i = 1; i <= "$MAX_RETRIES"; i++)); do
    tags=$(aws ec2 describe-tags \
      --region "$instance_region" \
      --filters "Name=resource-type,Values=instance" "Name=resource-id,Values=${instance_id}")
    count_tags=$(echo $tags | jq -r ".Tags? | length")
    if [[ "$count_tags" -gt 0 ]]; then
      log_info "This Instance $instance_id in $instance_region has Tags."
      echo "$tags"
      return
    else
      log_warn "This Instance $instance_id in $instance_region does not have any Tags."
      log_warn "Will sleep for $SLEEP_BETWEEN_RETRIES_SEC seconds and try again."
      sleep "$SLEEP_BETWEEN_RETRIES_SEC"
    fi
  done

  log_error "Could not find Instance Tags for $instance_id in $instance_region after $MAX_RETRIES retries."
  exit 1
}

function get_asg_size {
  local -r asg_name="$1"
  local -r aws_region="$2"
  local asg_json=""

  log_info "Looking up the size of the Auto Scaling Group $asg_name in $aws_region"
  asg_json=$(aws autoscaling describe-auto-scaling-groups --region "$aws_region" --auto-scaling-group-names "$asg_name")
  echo "$asg_json" | jq -r '.AutoScalingGroups[0].DesiredCapacity'
}

function get_cluster_size {
  local -r instance_tags="$1"
  local -r aws_region="$2"

  local asg_name=""
  asg_name=$(get_tag_value "$instance_tags" "$AWS_ASG_TAG_KEY")
  if [[ -z "$asg_name" ]]; then
    log_warn "This EC2 Instance does not appear to be part of an Auto Scaling Group, so cannot determine cluster size. Setting cluster size to 1."
    echo 1
  else
    get_asg_size "$asg_name" "$aws_region"
  fi
}

# Get the value for a specific tag from the tags JSON returned by the AWS describe-tags:
# https://docs.aws.amazon.com/cli/latest/reference/ec2/describe-tags.html
function get_tag_value {
  local -r tags="$1"
  local -r tag_key="$2"

  echo "$tags" | jq -r ".Tags[] | select(.Key == \"$tag_key\") | .Value"
}

function write_acl_policy {
  local -r policy_name="$1"
  local -r policy_hcl="$2"
  local -r token="$3"

  local token_arg

  if [[ ! "$token" == "" ]]; then
    token_arg="-token $token"
  else
    token_arg=""
  fi

  echo "$policy_hcl" | nomad acl policy apply $token_arg -description "$policy_name" $policy_name -
}

function generate_token {
  local -r policy_name="$1"
  local -r description="$2"
  local -r token="$3"

  if [[ ! "$token" == "" ]]; then
    token_arg="-token $token"
  else
    token_arg=""
  fi

  local -r generated_token=$(nomad acl token create $token_arg -name="$policy_name" -policy="$policy_name" | grep "Secret ID" | cut -d''='' -f 2 | xargs)

  echo $generated_token
}

function generate_bootstrap_acl_token {
  local -r max_retries="$1"
  local -r sleep_between_retries="$2"

  local token

  for ((i = 0; i < "$max_retries"; i++)); do
    token=$(nomad acl bootstrap -json | jq '.SecretID' -r)
    if [[ "$token" == "" ]]; then
      log_info "Token could not be obtained, retrying."
      sleep $sleep_between_retries
    else
      echo $token
      return
    fi
  done

  log_error "Unable to obtain ACL token. Aborting."
  exit 1
}

function generate_nomad_config {
  local readonly server="$1"
  local readonly client="$2"
  local readonly num_servers="$3"
  local readonly config_dir="$4"
  local readonly user="$5"
  local -r enable_acl="${6:-false}"
  local -r consul_cluster_tag_value="${7}"
  local -r enable_telemetry="${8}"
  local -r enable_vault="${9:-false}"
  local -r vault_addr="${10}"
  local -r vault_role="${11}"
  local -r vault_token="${12}"
  local -r cluster_tag_value="${13}"
  local -r node_class="${14}"
  local -r use_ip_for_node_name="${15:-false}"

  local readonly config_path="$config_dir/$NOMAD_CONFIG_FILE"

  local instance_id=""
  local instance_ip_address=""
  local instance_region=""
  local instance_availability_zone=""

  metadata_token=$(get_metadata_token)

  if [[ -z "$metadata_token" ]]; then
    log_error "could not retrieve IMDSv2 token. exiting. check if your launch template metadata options have http_tokens set to required and http_endpoint set to enabled."
    exit 1
  fi

  instance_id=$(get_instance_id "$metadata_token")
  instance_ip_address=$(get_instance_ip_address "$metadata_token")
  instance_region=$(get_instance_region "$metadata_token")
  availability_zone=$(get_instance_availability_zone "$metadata_token")

  local node_prefix="$instance_id"
  log_info "Defaulting Nomad node name base to AWS instance ID ($instance_id)."

  if [[ "$use_ip_for_node_name" == "true" ]] && [[ -n "$instance_ip_address" ]]; then
    log_info "Parameter --use-ip-for-node-name enabled. Using IP ($instance_ip_address) as prefix to ID ($instance_id) for Nomad node name."
    node_prefix=$instance_ip_address
  
  elif [[ "$use_ip_for_node_name" == "true" ]] && [[ -z "$instance_ip_address" ]]; then
    log_warn "Parameter --use-ip-for-node-name enabled, but instance IP is empty. Falling back to only instance ID ($instance_id)."
  fi

  local final_node_name=""
  if [[ -n "$cluster_tag_value" ]]; then
    final_node_name="$cluster_tag_value-$node_prefix"
    log_info "Prepending cluster tag value ($cluster_tag_value) to Nomad node name: $final_node_name."
  else
    final_node_name="$node_prefix"
    log_info "No cluster tag value. Nomad node name set to: $final_node_name."
  fi

  local server_config=""
  if [[ "$server" == "true" ]]; then
    server_config=$(
      cat <<EOF
server {
  enabled = true
  bootstrap_expect = $num_servers
}
EOF
    )
   # instance_id="$cluster_tag_value-$instance_id"

  fi

  local node_class_config=""
  if [[ ! -z "$node_class" ]] || [[ "$node_class" != "" ]]; then
  log_info "Setting nomad node class to $node_class"
    node_class_config=$(
      cat <<EOF
node_class = "$node_class"
EOF
    )
  fi

  local client_config=""
  if [[ "$client" == "true" ]]; then

    log_info "Creating client configuration"

    
      client_config=$(
        cat <<EOF
client {
  enabled = true
  $node_class_config
}
EOF
      )
    
   # instance_id="$cluster_tag_value-$instance_id"
  fi

  local acl_configuration=""
  if [[ "$enable_acl" == "true" ]]; then
    log_info "Creating ACL configuration"
    acl_configuration=$(
      cat <<EOF
acl = {
  enabled = true
}
EOF
    )
  fi

  local consul_config=""
  if [[ "$enable_acl" == "true" ]]; then
    local -r aws_region=$(aws_get_instance_region)
    log_info "Getting consul ACL token for nomad clients"
    if [[ -z "$consul_cluster_tag_value" ]]; then
      log_error "Provide consul cluster tag value to determine the AWS consul cluster & fetch ACL token"
      exit 1
    else
      consul_config=$(
        cat <<EOF
consul {
  address = "127.0.0.1:8500",
  token = "$(read_acl_token "$consul_cluster_tag_value" "nomad" "$aws_region" 1 0)"
}
EOF
      )
    fi
  else
    consul_config=$(
      cat <<EOF
consul {
 address = "127.0.0.1:8500"
 }
EOF
    )
  fi

  local vault_config=""
  if [[ "$enable_vault" == "true" ]]; then
    if [[ "$client" == "true" ]]; then
      log_info "generating vault client config"
      vault_config=$(
        cat <<EOF
vault {
  enabled = true
  address = "$vault_addr"
  create_from_role = "$vault_role"
}
EOF
      )
    else
      log_info "generating vault server config"
      if [ -z "$vault_token" ] || [ "$vault_token" == "" ]; then
        log_error "You must specify an option for the --vault-token parameter when --enable-vault and --server is specified."
        exit 1
      fi
      vault_config=$(
        cat <<EOF
vault {
  enabled = true
  address = "$vault_addr"
  token   = "$vault_token"
  create_from_role = "$vault_role"
}
EOF
      )
    fi
  fi

  local telemetry_config=""
  if [[ "$enable_telemetry" == "true" ]]; then
    log_info "generating telemetry config"
    telemetry_config=$(
      cat <<EOF
telemetry {
  collection_interval = "1s"
  disable_hostname = true
  prometheus_metrics = true
  publish_allocation_metrics = true
  publish_node_metrics = false
}
EOF
    )
  fi

  log_info "Creating default Nomad config file in $config_path"
  cat >"$config_path" <<EOF
datacenter = "$availability_zone"
name       = "$final_node_name"
region     = "$instance_region"
bind_addr  = "0.0.0.0"
advertise {
  http = "$instance_ip_address"
  rpc  = "$instance_ip_address"
  serf = "$instance_ip_address"
}
$acl_configuration
$client_config
$server_config
$vault_config

$consul_config

$telemetry_config
EOF
  chown "$user:$user" "$config_path"
}

function generate_systemd_config {
  local readonly systemd_config_path="$1"
  local readonly nomad_config_dir="$2"
  local readonly nomad_data_dir="$3"
  local readonly nomad_bin_dir="$4"
  local readonly nomad_sytemd_stdout="$5"
  local readonly nomad_sytemd_stderr="$6"
  local readonly nomad_user="$7"
  local readonly use_sudo="$8"
  shift 8
  local readonly environment=("$@")
  local readonly config_path="$nomad_config_dir/$NOMAD_CONFIG_FILE"

  if [[ "$use_sudo" == "true" ]]; then
    log_info "The --use-sudo flag is set, so running Nomad as the root user"
    nomad_user="root"
  fi

  log_info "Creating systemd config file to run Nomad in $systemd_config_path"

  local readonly unit_config=$(
    cat <<EOF
[Unit]
Description="HashiCorp Nomad"
Documentation=https://www.nomadproject.io/
Requires=network-online.target
After=network-online.target
ConditionalFileNotEmpty=$config_path
EOF
  )

  local readonly service_config=$(
    cat <<EOF
[Service]
User=$nomad_user
Group=$nomad_user
ExecStart=$nomad_bin_dir/nomad agent -config $nomad_config_dir -data-dir $nomad_data_dir
ExecReload=/bin/kill --signal HUP \$MAINPID
KillMode=process
Restart=on-failure
LimitNOFILE=65536
$(split_by_lines "Environment=" "${environment[@]}")
EOF
  )

  local log_config=""
  if [[ ! -z $nomad_sytemd_stdout ]]; then
    log_config+="StandardOutput=$nomad_sytemd_stdout\n"
  fi
  if [[ ! -z $nomad_sytemd_stderr ]]; then
    log_config+="StandardError=$nomad_sytemd_stderr\n"
  fi

  local readonly install_config=$(
    cat <<EOF
[Install]
WantedBy=multi-user.target
EOF
  )

  echo -e "$unit_config" >"$systemd_config_path"
  echo -e "$service_config" >>"$systemd_config_path"
  echo -e "$log_config" >>"$systemd_config_path"
  echo -e "$install_config" >>"$systemd_config_path"
}

function start_nomad {
  log_info "Reloading systemd config and starting Nomad"

  sudo systemctl daemon-reload
  sudo systemctl enable nomad.service
  sudo systemctl restart nomad.service
}

# Based on: http://unix.stackexchange.com/a/7732/215969
function get_owner_of_path {
  local readonly path="$1"
  ls -ld "$path" | awk '{print $3}'
}

function run {
  local server="false"
  local client="false"
  local num_servers=""
  local config_dir=""
  local data_dir=""
  local bin_dir=""
  local systemd_stdout=""
  local systemd_stderr=""
  local user=""
  local skip_nomad_config="false"
  local use_sudo=""
  local environment=()
  local all_args=()
  local consul_cluster_tag_value=""
  local vault_addr=""
  local enable_vault="false"
  local use_ip_for_node_name="false" 

  while [[ $# > 0 ]]; do
    local key="$1"

    case "$key" in
    --server)
      server="true"
      ;;
    --client)
      client="true"
      ;;
    --num-servers)
      num_servers="$2"
      shift
      ;;
    --config-dir)
      assert_not_empty "$key" "$2"
      config_dir="$2"
      shift
      ;;
    --data-dir)
      assert_not_empty "$key" "$2"
      data_dir="$2"
      shift
      ;;
    --bin-dir)
      assert_not_empty "$key" "$2"
      bin_dir="$2"
      shift
      ;;
    --systemd-stdout)
      assert_not_empty "$key" "$2"
      systemd_stdout="$2"
      shift
      ;;
    --systemd-stderr)
      assert_not_empty "$key" "$2"
      systemd_stderr="$2"
      shift
      ;;
    --user)
      assert_not_empty "$key" "$2"
      user="$2"
      shift
      ;;
    --cluster-tag-key)
      assert_not_empty "$key" "$2"
      cluster_tag_key="$2"
      shift
      ;;
    --cluster-tag-value)
      assert_not_empty "$key" "$2"
      cluster_tag_value="$2"
      shift
      ;;
    --consul-cluster-tag-value)
      assert_not_empty "$key" "$2"
      consul_cluster_tag_value="$2"
      shift
      ;;
    --vault-addr)
      assert_not_empty "$key" "$2"
      vault_addr="$2"
      shift
      ;;
    --vault-role)
      assert_not_empty "$key" "$2"
      vault_role="$2"
      shift
      ;;
    --vault-token)
      assert_not_empty "$key" "$2"
      vault_token="$2"
      shift
      ;;
    --enable_telemetry)
      enable_telemetry="true"
      ;;
    --node-class)
      assert_not_empty "$key" "$2"
      node_class="$2"
      shift
      ;;
    --skip-nomad-config)
      skip_nomad_config="true"
      ;;
    --use-sudo)
      use_sudo="true"
      ;;
    --environment)
      assert_not_empty "$key" "$2"
      environment+=("$2")
      shift
      ;;
    --enable-acl)
      enable_acl="true"
      ;;
    --enable-vault)
      enable_vault="true"
      ;;
    --acl-storage-type)
      assert_not_empty "$key" "$2"
      acl_storage_type="$2"
      shift
      ;;
    --use-ip-for-node-name)
      use_ip_for_node_name="$2"
      shift
      ;;
    --help)
      print_usage
      exit
      ;;
    *)
      log_error "Unrecognized argument: $key"
      print_usage
      exit 1
      ;;
    esac

    shift
  done

  if [[ "$enable_acl" == "true" ]]; then
    if [ -z "$acl_storage_type" ] || [ "$acl_storage_type" == "" ]; then
      log_error "You must specify an option for the --acl-storage-type parameter when --enable-acl is specified."
      exit 1
    fi

    local storage_type_matched="false"

    # Source appropriate storage provider script
    case "$acl_storage_type" in
    'ssm' | 'SSM')
      storage_type_matched="true"
      source ${SCRIPT_DIR}/nomad-bootstrap-ssm.sh
      ;;

    *)
      if [ $storage_type_matched="false" ]; then
        log_error "ACL storage type '${acl_storage_type}' is not supported."
        exit 1
      fi
      ;;

    esac
  fi

  if [[ "$server" == "true" ]]; then
    assert_not_empty "--num-servers" "$num_servers"
  fi

  if [[ "$server" == "false" && "$client" == "false" ]]; then
    log_error "At least one of --server or --client must be set"
    exit 1
  fi

  if [[ "$server" == "true" ]] && [[ "$enable_vault" == "true" ]]; then
    assert_not_empty "--vault-addr" "$vault_addr"
    assert_not_empty "--vault-role" "$vault_role"
    assert_not_empty "--vault-token" "$vault_token"
  fi

  if [[ "$client" == "true" ]] && [[ "$enable_vault" == "true" ]]; then
    assert_not_empty "--vault-addr" "$vault_addr"
    assert_not_empty "--vault-role" "$vault_role"
  fi

  if [[ -z "$use_sudo" ]]; then
    if [[ "$client" == "true" ]]; then
      use_sudo="true"
    else
      use_sudo="false"
    fi
  fi

  assert_is_installed "systemctl"
  assert_is_installed "aws"
  assert_is_installed "curl"
  assert_is_installed "jq"

  if [[ -z "$config_dir" ]]; then
    config_dir=$(cd "$SCRIPT_DIR/../config" && pwd)
  fi

  if [[ -z "$data_dir" ]]; then
    data_dir=$(cd "$SCRIPT_DIR/../data" && pwd)
  fi

  if [[ -z "$bin_dir" ]]; then
    bin_dir=$(cd "$SCRIPT_DIR/../bin" && pwd)
  fi

  # If $systemd_stdout and/or $systemd_stderr are empty, we leave them empty so that generate_systemd_config will use systemd's defaults (journal and inherit, respectively)

  if [[ -z "$user" ]]; then
    user=$(get_owner_of_path "$config_dir")
  fi

  if [[ "$skip_nomad_config" == "true" ]]; then
    log_info "The --skip-nomad-config flag is set, so will not generate a default Nomad config file."
  else
    generate_nomad_config "$server" "$client" "$num_servers" "$config_dir" "$user" "$enable_acl" "$consul_cluster_tag_value" "$enable_telemetry" "$enable_vault" "$vault_addr" "$vault_role" "$vault_token" "$cluster_tag_value" "$node_class"
  fi

  generate_systemd_config "$SYSTEMD_CONFIG_PATH" "$config_dir" "$data_dir" "$bin_dir" "$systemd_stdout" "$systemd_stderr" "$user" "$use_sudo" "${environment[@]}"
  start_nomad

  if [[ "$enable_acl" == "true" ]] && [ "${server}" == "true" ]; then
    local -r asg_name=$(aws_wrapper_get_asg_name $MAX_RETRIES $SLEEP_BETWEEN_RETRIES_SEC)
    local -r aws_region=$(aws_get_instance_region)
    local -r instance_id=$(aws_get_instance_id)

    local bootstrap_token

    # Calculate the rally point server for the ASG
    local -r rally_point_hostname=$(aws_wrapper_get_asg_rally_point $asg_name $aws_region "false")
    log_info "Calculated rally point instance is $rally_point_hostname."
    local -r local_hostname=$(aws_wrapper_get_hostname)
    log_info "Local hostname is $local_hostname"

    if [[ "$rally_point_hostname" == "$local_hostname" ]]; then
      log_info "Checking if bootstrap token already exists"
      local -r existing_token=$(read_acl_token $cluster_tag_value "bootstrap" $aws_region 1 0 "true")

      if [[ "$existing_token" == "" ]] && [ "${server}" == "true" ]; then
        log_info "Generating bootstrap ACL token"
        bootstrap_token=$(generate_bootstrap_acl_token $MAX_RETRIES $SLEEP_BETWEEN_RETRIES_SEC)
        log_info "Persisting bootstrap token to SSM parameter"
        write_acl_token $bootstrap_token $cluster_tag_value "bootstrap" $aws_region "ssm"

        log_info "Checking if additional policies and tokens are needed"
        POLICY_DIR="/opt/nomad/policy"
        if [[ -d "$POLICY_DIR" ]] && [ "${server}" == "true" ]; then
          if [ "$(ls -A $POLICY_DIR)" ]; then
            for policy in $POLICY_DIR/*; do
              policy_name="$(basename $policy | cut -d "." -f1)"
              policy_hcl=$(cat $policy)
              write_acl_policy "$policy_name" "$policy_hcl" "$bootstrap_token"
              log_info "Generating token for the policy - $policy_name"
              local policy_token=$(generate_token "$policy_name" "$policy_name agent policy" $bootstrap_token)
              if [[ "$?" -eq 0 ]] && [ -n "${policy_token}" ]; then
                write_acl_token $policy_token $cluster_tag_value $policy_name $aws_region "ssm"
              else
                log_warn "Policy token cannot be generated. Please check the policies."
              fi
            done
          else
            log_warn "Policy directory is empty"
          fi
        else
          log_warn "Policy directory does not exists. So not generating any policies and tokens"
        fi

      else
        log_info "Bootstrap token already exists, skipping"
      fi
    fi

    # If the bootstrap token isn't already read (i.e. if this is running on the non rally point node)
    # then we need to read it.
    if [[ -z "$bootstrap_token" ]]; then
      log_info "Acquiring bootstrap token"
      bootstrap_token=$(read_acl_token $cluster_tag_value "bootstrap" $aws_region)
    fi
  fi
}

run "$@"
